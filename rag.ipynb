{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "from autogen import AssistantAgent, LLMConfig\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "from autogen.agents.experimental import DocAgent\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from dotenv import load_dotenv\n",
    "from autogen.agents.experimental import DocAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {'cache_seed': 42,\n",
    "                    'temperature': 1.,\n",
    "                    'top_p': 0.05,\n",
    "                    'config_list': [{'model': 'gpt-4o-mini',\n",
    "                                    'api_key': os.getenv('OPENAI_API_KEY'),\n",
    "                                    'api_type': 'openai'}],\n",
    "                    'timeout': 1200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "DOC_PATH = \"data/UnderstandingDeepLearning_DiffusionModels.pdf\"\n",
    "CHROMA_PATH = \"database\"\n",
    "QUERY = \"What is the difference between diffusion models and GANs?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/UnderstandingDeepLearning_DiffusionModels.pdf'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOC_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.agents.experimental.document_agent.chroma_query_engine:Using existing collection summarise from the database.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to DocAgent):\n",
      "\n",
      "ingest data/UnderstandingDeepLearning_DiffusionModels.pdf and answer What is the difference between diffusion models and GANs?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33m_User\u001b[0m (to chat_manager):\n",
      "\n",
      "ingest data/UnderstandingDeepLearning_DiffusionModels.pdf and answer What is the difference between diffusion models and GANs?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: DocumentTriageAgent\n",
      "\u001b[0m\n",
      "\u001b[33mDocumentTriageAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "{\"ingestions\":[{\"path_or_url\":\"data/UnderstandingDeepLearning_DiffusionModels.pdf\"}],\"queries\":[{\"query_type\":\"RAG_QUERY\",\"query\":\"What is the difference between diffusion models and GANs?\"}]}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: TaskManagerAgent\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mTaskManagerAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_5OsdM7VTtHW6IabGemvMnqBS): initiate_tasks *****\u001b[0m\n",
      "Arguments: \n",
      "{\"task_init_info\":{\"ingestions\":[{\"path_or_url\":\"data/UnderstandingDeepLearning_DiffusionModels.pdf\"}],\"queries\":[{\"query_type\":\"RAG_QUERY\",\"query\":\"What is the difference between diffusion models and GANs?\"}]}}\n",
      "\u001b[32m*******************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: _Group_Tool_Executor\n",
      "\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION initiate_tasks...\n",
      "Call ID: call_5OsdM7VTtHW6IabGemvMnqBS\n",
      "Input arguments: {'task_init_info': {'ingestions': [{'path_or_url': 'data/UnderstandingDeepLearning_DiffusionModels.pdf'}], 'queries': [{'query_type': 'RAG_QUERY', 'query': 'What is the difference between diffusion models and GANs?'}]}}\u001b[0m\n",
      "\u001b[33m_Group_Tool_Executor\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_5OsdM7VTtHW6IabGemvMnqBS) *****\u001b[0m\n",
      "Updated context variables with task decisions\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: TaskManagerAgent\n",
      "\u001b[0m\n",
      "\u001b[33mTaskManagerAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "[Handing off to DoclingDocIngestAgent]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: DoclingDocIngestAgent\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mDoclingDocIngestAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_Wkos3RxYmB0K4jEY3GJDTYm4): data_ingest_task *****\u001b[0m\n",
      "Arguments: \n",
      "{}\n",
      "\u001b[32m*********************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.agents.experimental.document_agent.document_utils:Detected file. Returning file path...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "Next speaker: _Group_Tool_Executor\n",
      "\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION data_ingest_task...\n",
      "Call ID: call_Wkos3RxYmB0K4jEY3GJDTYm4\n",
      "Input arguments: {}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:docling.document_converter:Going to convert document batch...\n",
      "INFO:docling.document_converter:Initializing pipeline for StandardPdfPipeline with options hash abf069e0fb0f219e247d3d2b243ad857\n",
      "INFO:docling.models.factories.base_factory:Loading plugin 'docling_defaults'\n",
      "INFO:docling.models.factories:Registered ocr engines: ['easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "/home/ljf1/dis/MCPAgents/mcp_env/lib/python3.12/site-packages/docling/models/easyocr_model.py:69: UserWarning: Deprecated field. Better to set the `accelerator_options.device` in `pipeline_options`. When `use_gpu and accelerator_options.device == AcceleratorDevice.CUDA` the GPU is used to run EasyOCR. Otherwise, EasyOCR runs in CPU.\n",
      "  warnings.warn(\n",
      "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n",
      "INFO:easyocr.easyocr:Download complete\n",
      "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n",
      "INFO:easyocr.easyocr:Download complete.\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.models.factories.base_factory:Loading plugin 'docling_defaults'\n",
      "INFO:docling.models.factories:Registered picture descriptions: ['vlm', 'api']\n",
      "INFO:docling.pipeline.base_pipeline:Processing document UnderstandingDeepLearning_DiffusionModels.pdf\n",
      "INFO:docling.document_converter:Finished converting document UnderstandingDeepLearning_DiffusionModels.pdf in 90.87 sec.\n",
      "INFO:autogen.agents.experimental.document_agent.parser_utils:Document converted in 90.97 seconds.\n",
      "DEBUG:autogen.agents.experimental.document_agent.parser_utils:Document UnderstandingDeepLearning_DiffusionModels.pdf converted.\n",
      "Saved markdown output to: /home/ljf1/dis/mcp_hackathon/parsed_docs\n",
      "DEBUG:autogen.agents.experimental.document_agent.parser_utils:item-0 at level 0: unspecified: group _root_\n",
      "  item-1 at level 1: section_header: Chapter 18\n",
      "  item-2 at level 1: section_header: Diusion models\n",
      "  item-3 at level 1: text: Chapt ... ower bound.\n",
      "  item-4 at level 1: text: This  ... is chapter.\n",
      "  item-5 at level 1: section_header: 18.1 Overview\n",
      "  item-6 at level 1: text: A di ... erministic.\n",
      "  item-7 at level 1: text: In th ... etween each\n",
      "  item-8 at level 1: text: The e ... he decoder.\n",
      "  item-9 at level 1: picture\n",
      "    item-9 at level 2: caption: Figure 18.1 Diusion models. The encoder (forward, or diusion process) maps the input x through a series of latent variables z 1    z T . This process is prespecied and gradually mixes the data with noise until only noise remains. The decoder (reverse process) is learned and passes the data back through the latent variables, removing noise at each stage. After training, new examples are generated by sampling noise vectors z T and passing them through the decoder.\n",
      "    item-10 at level 2: caption: Figur ... he decoder.\n",
      "  item-11 at level 1: text: adjac ... he decoder.\n",
      "  item-12 at level 1: text: In se ... xt prompts.\n",
      "  item-13 at level 1: section_header: 18.2  ... rd process)\n",
      "  item-14 at level 1: text: The d ... cording to:\n",
      "  item-15 at level 1: formula: \n",
      "  item-16 at level 1: text: where ... written as:\n",
      "  item-17 at level 1: footnote: 1 Not ... back again.\n",
      "  item-18 at level 1: section_header: Problem 18.1\n",
      "  item-19 at level 1: picture\n",
      "    item-19 at level 2: caption: Figure 18.2 Forward process. a) We consider one-dimensional data x with T = 100 latent variables z , 1    , z 100 and β = 0 03  at all steps. Three values of x (gray, cyan, and orange) are initialized (top row). These are propagated through z , 1    , z 100 . At each step, the variable is updated by attenuating its value by √ 1 -β and adding noise with mean zero and variance β (equation 18.1). Accordingly, the three examples noisily propagate through the variables with a tendency to move toward zero. b) The conditional probabilities Pr z ( 1  x ) and Pr z ( t  z t -1 ) are normal distributions with a mean that is slightly closer to zero than the current point and a xed variance β t (equation 18.2).\n",
      "    item-20 at level 2: caption: Figur ... tion 18.2).\n",
      "  item-21 at level 1: formula: \n",
      "  item-22 at level 1: text: The j ... input x is:\n",
      "  item-23 at level 1: text: This  ... ribution. 2\n",
      "  item-24 at level 1: formula: \n",
      "  item-25 at level 1: footnote: 2 We  ... us chapter.\n",
      "  item-26 at level 1: picture\n",
      "    item-26 at level 2: caption: Figure 18.3 Diusion kernel. a) The point x ∗ =2 0  is propagated through the latent variables using equation 18.1 (ve paths shown in gray). The diusion kernel q z ( t  x ∗ ) is the probability distribution over variable z t given that we started from x ∗ . It can be computed in closed-form and is a normal distribution whose mean moves toward zero and whose variance increases as t increases. Heatmap shows q z ( t  x ∗ ) for each variable. Cyan lines show ± 2 standard deviations from the mean. b) The diusion kernel q z ( t  x ∗ ) is shown explicitly for t = 20 40 80 , , . In practice, the diusion kernel allows us to sample a latent variable z t corresponding to a given x ∗ without computing the intermediate variables z , 1    , z t -1 . When t becomes very large, the diusion kernel becomes a standard normal.\n",
      "    item-27 at level 2: caption: Figur ... ard normal.\n",
      "  item-28 at level 1: picture\n",
      "    item-28 at level 2: caption: Figure 18.4 Marginal distributions. a) Given an initial density Pr x ( ) (top row), the diusion process gradually blurs the distribution as it passes through the latent variables z t and moves it toward a standard normal distribution. Each subsequent horizontal line of heatmap represents a marginal distribution q z ( t ) . b) The top graph shows the initial distribution Pr x ( ) . The other two graphs show the marginal distributions q z ( 20 ) and q z ( 60 ) , respectively.\n",
      "    item-29 at level 2: caption: Figur ... spectively.\n",
      "  item-30 at level 1: section_header: 18.2. ... ( z t  x )\n",
      "  item-31 at level 1: text: To tr ... gure 18.3).\n",
      "  item-32 at level 1: text: To de ... rd process:\n",
      "  item-33 at level 1: formula: \n",
      "  item-34 at level 1: text: Subst ... nd, we get:\n",
      "  item-35 at level 1: formula: \n",
      "  item-36 at level 1: text: The l ...  18.2), so:\n",
      "  item-37 at level 1: formula: \n",
      "  item-38 at level 1: text: If we ...  show that:\n",
      "  item-39 at level 1: text: where ... stribution.\n",
      "  item-40 at level 1: formula: \n",
      "  item-41 at level 1: formula: \n",
      "  item-42 at level 1: text: where ... istic form:\n",
      "  item-43 at level 1: text: For a ... z t  x ) .\n",
      "  item-44 at level 1: section_header: 18.2. ... s q ( z t )\n",
      "  item-45 at level 1: text: The m ... ch starting\n",
      "  item-46 at level 1: section_header: Problem 18.2\n",
      "  item-47 at level 1: section_header: Problem 18.3\n",
      "  item-48 at level 1: text: point ... xcept z t :\n",
      "  item-49 at level 1: formula: \n",
      "  item-50 at level 1: text: where ... ation 18.3.\n",
      "  item-51 at level 1: text: Howev ... ntly write:\n",
      "  item-52 at level 1: formula: \n",
      "  item-53 at level 1: text: Hence ...  Pr ( x ) .\n",
      "  item-54 at level 1: section_header: 18.2. ...  -1  z t )\n",
      "  item-55 at level 1: text: We de ... ayes' rule:\n",
      "  item-56 at level 1: formula: \n",
      "  item-57 at level 1: text: This  ...  z t -1 ) .\n",
      "  item-58 at level 1: text: For t ... stribution.\n",
      "  item-59 at level 1: section_header: 18.2. ...  z t , x )\n",
      "  item-60 at level 1: text: There ... istributed.\n",
      "  item-61 at level 1: text: Hence ... he training\n",
      "  item-62 at level 1: text: Appen ... inalization\n",
      "  item-63 at level 1: text: Noteb ... ion encoder\n",
      "  item-64 at level 1: text: Appen ... Bayes' rule\n",
      "  item-65 at level 1: picture\n",
      "    item-65 at level 2: caption: Figure 18.5 Conditional distribution q z ( t -1  z t ) . a) The marginal densities q z ( t ) with three points z ∗ t highlighted. b) The probability q z ( t -1  z ∗ t ) (cyan curves) is computed via Bayes' rule and is proportional to q z ( ∗ t  z t -1 ) q z ( t -1 ) . In general, it is not normally distributed (top graph), although often the normal is a good approximation (bottom two graphs). The rst likelihood term q z ( ∗ t  z t -1 ) is normal in z t -1 (equation 18.2) with a mean that is slightly further from zero than z ∗ t (brown curves). The second term is the marginal density q z ( t -1 ) (gray curves).\n",
      "    item-66 at level 2: caption: Figur ... ay curves).\n",
      "  item-67 at level 1: picture\n",
      "    item-67 at level 2: caption: Figure 18.6 Conditional distribution q z ( t -1  z , x t ) . a) Diusion kernel for x ∗ = -2 1  with three points z ∗ t highlighted. b) The probability q z ( t - ∗ 1  z ∗ t , x ∗ ) is computed via Bayes' rule and is proportional to q z ( ∗ t  z t -1 ) q z ( t -1  x ) . This is normally distributed and can be computed in closed form. The rst likelihood term q z ( ∗ t  z t -1 ) is normal in z t -1 (equation 18.2) with a mean that is slightly further from zero than z ∗ t (brown curves). The second term is the diusion kernel q z ( t -1  x ∗ ) (gray curves).\n",
      "    item-68 at level 2: caption: Figur ... ay curves).\n",
      "  item-69 at level 1: text: data  ... ayes' rule:\n",
      "  item-70 at level 1: formula: \n",
      "  item-71 at level 1: text: where ... s identity:\n",
      "  item-72 at level 1: formula: \n",
      "  item-73 at level 1: text: to re ... n identity:\n",
      "  item-74 at level 1: formula: \n",
      "  item-75 at level 1: text: to co ... hich gives:\n",
      "  item-76 at level 1: formula: \n",
      "  item-77 at level 1: text: Note  ... stribution.\n",
      "  item-78 at level 1: section_header: 18.3  ... se process)\n",
      "  item-79 at level 1: text: When  ... tributions:\n",
      "  item-80 at level 1: formula: \n",
      "  item-81 at level 1: text: Appen ... f variables\n",
      "  item-82 at level 1: text: Problems 18.4-18.5\n",
      "  item-83 at level 1: text: Problem 18.6\n",
      "  item-84 at level 1: section_header: Appen ... inalization\n",
      "  item-85 at level 1: text: where ... reasonable.\n",
      "  item-86 at level 1: text: We ge ... 1 , ϕ 1 ) .\n",
      "  item-87 at level 1: section_header: 18.4 Training\n",
      "  item-88 at level 1: text: The j ...  z t  is:\n",
      "  item-89 at level 1: formula: \n",
      "  item-90 at level 1: text: The l ...  variables:\n",
      "  item-91 at level 1: formula: \n",
      "  item-92 at level 1: text: To tr ... ameters ϕ :\n",
      "  item-93 at level 1: formula: \n",
      "  item-94 at level 1: text: We ca ... on 17.3.1).\n",
      "  item-95 at level 1: section_header: 18.4. ... ound (ELBO)\n",
      "  item-96 at level 1: text: To de ... on 17.3.2):\n",
      "  item-97 at level 1: formula: \n",
      "  item-98 at level 1: text: This  ... und (ELBO):\n",
      "  item-99 at level 1: formula: \n",
      "  item-100 at level 1: text: In th ... gure 17.6).\n",
      "  item-101 at level 1: section_header: 18.4. ... ng the ELBO\n",
      "  item-102 at level 1: text: We no ... spectively:\n",
      "  item-103 at level 1: formula: \n",
      "  item-104 at level 1: text: Then  ... econd term:\n",
      "  item-105 at level 1: formula: \n",
      "  item-106 at level 1: text: Subst ... sult gives:\n",
      "  item-107 at level 1: text: where ... ayes' rule.\n",
      "  item-108 at level 1: formula: \n",
      "  item-109 at level 1: text: Appen ... Bayes' rule\n",
      "  item-110 at level 1: text: Appen ... stributions\n",
      "  item-111 at level 1: text: Problem 18.8\n",
      "  item-112 at level 1: text: where ... r ( z T ) .\n",
      "  item-113 at level 1: text: The s ... O is hence:\n",
      "  item-114 at level 1: text: Probl ... endix C.5.1\n",
      "  item-115 at level 1: text: where ... blem 18.7).\n",
      "  item-116 at level 1: formula: \n",
      "  item-117 at level 1: text: KL divergence\n",
      "  item-118 at level 1: section_header: 18.4. ... ng the ELBO\n",
      "  item-119 at level 1: text: The  ... tion 18.16:\n",
      "  item-120 at level 1: formula: \n",
      "  item-121 at level 1: text: The K ... spectively:\n",
      "  item-122 at level 1: text: and i ... z 1  x ) .\n",
      "  item-123 at level 1: formula: \n",
      "  item-124 at level 1: text: The K ... onstant C :\n",
      "  item-125 at level 1: formula: \n",
      "  item-126 at level 1: picture\n",
      "    item-126 at level 2: caption: Figure 18.7 Fitted Model. a) Individual samples can be generated by sampling from the standard normal distribution Pr z ( T ) (bottom row) and then sampling z T -1 from Pr z ( T -1  z T ) = Norm z T -1 [ f T [ z T , ϕ T ] , σ 2 T I ] and so on until we reach x (ve paths shown). The estimated marginal densities (heatmap) are the aggregation of these samples and are similar to the true marginal densities (gure 18.4). b) The estimated distribution Pr z ( t -1  z t ) (brown curve) is a reasonable approximation to the true posterior of the diusion model q z ( t -1  z t ) (cyan curve) from gure 18.5. The marginal distributions Pr z ( t ) and q z ( t ) of the estimated and true models (dark blue and gray curves, respectively) are also similar.\n",
      "    item-127 at level 2: caption: Figur ... so similar.\n",
      "  item-128 at level 1: section_header: 18.4. ... ss function\n",
      "  item-129 at level 1: text: To t ... s function:\n",
      "  item-130 at level 1: section_header: reconstruction term\n",
      "  item-131 at level 1: formula: \n",
      "  item-132 at level 1: text: where ... on step t .\n",
      "  item-133 at level 1: text: Figur ... gure 18.7.\n",
      "  item-134 at level 1: picture\n",
      "  item-135 at level 1: section_header: 18.4. ... g procedure\n",
      "  item-136 at level 1: text: This  ... ed data x .\n",
      "  item-137 at level 1: text: Noteb ... usion model\n",
      "  item-138 at level 1: text: Figur ... l networks.\n",
      "  item-139 at level 1: section_header: 18.5  ... ss function\n",
      "  item-140 at level 1: text: Altho ... ion 18.29).\n",
      "  item-141 at level 1: section_header: 18.5. ... n of target\n",
      "  item-142 at level 1: text: The o ... s given by:\n",
      "  item-143 at level 1: formula: \n",
      "  item-144 at level 1: text: It fo ... dded to it:\n",
      "  item-145 at level 1: formula: \n",
      "  item-146 at level 1: text: Subst ... 8.29 gives:\n",
      "  item-147 at level 1: formula: \n",
      "  item-148 at level 1: text: where ... er, we get:\n",
      "  item-149 at level 1: formula: \n",
      "  item-150 at level 1: text: Subst ... ), we have:\n",
      "  item-151 at level 1: text: where ... e and four.\n",
      "  item-152 at level 1: formula: \n",
      "  item-153 at level 1: section_header: 18.5. ...  of network\n",
      "  item-154 at level 1: text: Now w ... reate z t :\n",
      "  item-155 at level 1: formula: \n",
      "  item-156 at level 1: text: Draft ... @gmail.com.\n",
      "  item-157 at level 1: text: Problem 18.9\n",
      "  item-158 at level 1: text: Problem 18.10\n",
      "  item-159 at level 1: section_header: Problem 18.11\n",
      "  item-160 at level 1: text: Subst ...  criterion:\n",
      "  item-161 at level 1: formula: \n",
      "  item-162 at level 1: formula: \n",
      "  item-163 at level 1: text: Subst ... mplies to:\n",
      "  item-164 at level 1: formula: \n",
      "  item-165 at level 1: formula: \n",
      "  item-166 at level 1: text: where ... tants C i .\n",
      "  item-167 at level 1: text: In pr ... ormulation:\n",
      "  item-168 at level 1: formula: \n",
      "  item-169 at level 1: section_header: 18.6 Implementation\n",
      "  item-170 at level 1: text: This  ... -consuming.\n",
      "  item-171 at level 1: section_header: Algor ... el training\n",
      "  item-172 at level 1: code: Input ... l converged\n",
      "  item-173 at level 1: section_header: Algor ... 2: Sampling\n",
      "  item-174 at level 1: code: Input ... thout noise\n",
      "  item-175 at level 1: section_header: 18.6. ... n to images\n",
      "  item-176 at level 1: text: Dius ... l position.\n",
      "  item-177 at level 1: text: A lar ... ood images.\n",
      "  item-178 at level 1: section_header: 18.6. ... ation speed\n",
      "  item-179 at level 1: text: The l ... ard process\n",
      "  item-180 at level 1: picture\n",
      "    item-180 at level 2: caption: Figure 18.9 U-Net as used in diusion models for images. The network aims to predict the noise that was added to the image. It consists of an encoder which reduces the scale and increases the number of channels and a decoder which increases the scale and reduces the number of channels. The encoder representations are concatenated to their partner in the decoder. Connections between adjacent representations consist of residual blocks, and periodic global self-attention in which every spatial position interacts with every other spatial position. A single network is used for all time steps, by passing a sinusoidal time embedding (gure 12.5) through a shallow neural network and adding the result to the channels at every spatial position at every stage of the U-Net.\n",
      "    item-181 at level 2: caption: Figur ...  the U-Net.\n",
      "  item-182 at level 1: text: with  ... ure 18.10).\n",
      "  item-183 at level 1: text: Noteb ... sion models\n",
      "  item-184 at level 1: text: Among ... ive models.\n",
      "  item-185 at level 1: section_header: 18.6. ...  generation\n",
      "  item-186 at level 1: text: If th ... ng an extra\n",
      "  item-187 at level 1: picture\n",
      "    item-187 at level 2: caption: Figure 18.10 Dierent diusion processes that are compatible with the same model. a) Five sampled trajectories of the reparameterized model superimposed on the ground truth marginal distributions. Top row represents Pr ( x ) and subsequent rows represent q ( x t ) . b) Histogram of samples generated from reparameterized model plotted alongside ground truth density curve Pr ( x ) . The same trained model is compatible with a family of diusion models (and corresponding updates in the opposite direction), including the denoising diusion implicit model (DDIM), which is deterministic and does not add noise at each step. c) Five trajectories from DDIM. d) Histogram of samples from DDIM. The same model is also compatible with accelerated diusion models that skip inference steps for increased sampling speed. e) Five trajectories from accelerated model. f) Histogram of samples from accelerated model.\n",
      "    item-188 at level 2: caption: Figur ... ated model.\n",
      "  item-189 at level 1: text: term  ... 2 to yield:\n",
      "  item-190 at level 1: formula: \n",
      "  item-191 at level 1: text: The n ... ore likely.\n",
      "  item-192 at level 1: text: Class ... information\n",
      "  item-193 at level 1: picture\n",
      "    item-193 at level 2: caption: Figure 18.11 Cascaded conditional generation based on a text prompt. a) A diusion model consisting of a series of U-Nets is used to generate a 64 × 64 image. b) This generation is conditioned on a sentence embedding computed by a language model. c) A higher resolution 256 × 256 image is generated and conditioned on the smaller image and the text encoding. d) This is repeated to create a 1024 × 1024 image. e) Final image sequence. Adapted from Saharia et al. (2022b).\n",
      "    item-194 at level 2: caption: Figur ... l. (2022b).\n",
      "  item-195 at level 1: text: Problem 18.12\n",
      "  item-196 at level 1: text: durin ... ure 15.10).\n",
      "  item-197 at level 1: section_header: 18.6. ... ion quality\n",
      "  item-198 at level 1: text: As fo ...  the widths\n",
      "  item-199 at level 1: text: of th ... ve results.\n",
      "  item-200 at level 1: text: Third ... ure 18.11).\n",
      "  item-201 at level 1: text: Combi ... me caption.\n",
      "  item-202 at level 1: section_header: 18.7 Summary\n",
      "  item-203 at level 1: text: Dius ... ormulation.\n",
      "  item-204 at level 1: text: For i ... is results.\n",
      "  item-205 at level 1: section_header: Notes\n",
      "  item-206 at level 1: text: Denoi ... At the time\n",
      "  item-207 at level 1: picture\n",
      "  item-208 at level 1: caption: Figur ... hol (2021).\n",
      "  item-209 at level 1: picture\n",
      "    item-209 at level 2: caption: transparent sculpture of a duck made out of glass\n",
      "    item-210 at level 2: caption: trans ... ut of glass\n",
      "  item-211 at level 1: picture\n",
      "  item-212 at level 1: picture\n",
      "    item-212 at level 2: caption: A brain rocketship heading towards the moon riding\n",
      "    item-213 at level 2: caption: A bra ... moon riding\n",
      "  item-214 at level 1: picture\n",
      "  item-215 at level 1: picture\n",
      "  item-216 at level 1: picture\n",
      "    item-216 at level 2: caption: An angry duck doing weightlifting at the gym heavy\n",
      "    item-217 at level 2: caption: An an ... e gym heavy\n",
      "  item-218 at level 1: picture\n",
      "  item-219 at level 1: picture\n",
      "  item-220 at level 1: caption: couple of glasses\n",
      "  item-221 at level 1: picture\n",
      "    item-221 at level 2: caption: New York skyline with Hello World\n",
      "    item-222 at level 2: caption: New Y ... Hello World\n",
      "  item-223 at level 1: caption: Figur ... l. (2022b).\n",
      "  item-224 at level 1: text: of wr ... al. (2022).\n",
      "  item-225 at level 1: text: Appli ... as a prior.\n",
      "  item-226 at level 1: text: Dier ... audio data.\n",
      "  item-227 at level 1: text: Alter ... pixelating.\n",
      "  item-228 at level 1: text: Compa ... rpretation.\n",
      "  item-229 at level 1: text: Impro ... s function.\n",
      "  item-230 at level 1: text: Kingm ...  the model.\n",
      "  item-231 at level 1: text: Ho et ... ent values.\n",
      "  item-232 at level 1: text: Impro ... r approach.\n",
      "  item-233 at level 1: text: Song  ... be applied.\n",
      "  item-234 at level 1: text: Song  ...  synthesis.\n",
      "  item-235 at level 1: text: Sampl ... usion step.\n",
      "  item-236 at level 1: text: Salim ... e sampling.\n",
      "  item-237 at level 1: text: Condi ... ic samples.\n",
      "  item-238 at level 1: text: The s ... gure 18.9).\n",
      "  item-239 at level 1: text: Exist ... ala, 2023).\n",
      "  item-240 at level 1: text: Text- ... al., 2021),\n",
      "  item-241 at level 1: text: which ... mage model.\n",
      "  item-242 at level 1: text: Conne ... approaches.\n",
      "  item-243 at level 1: section_header: Problems\n",
      "  item-244 at level 1: text: Probl ... the update:\n",
      "  item-245 at level 1: formula: \n",
      "  item-246 at level 1: text: then  ... s the same.\n",
      "  item-247 at level 1: text: Probl ... e variable:\n",
      "  item-248 at level 1: formula: \n",
      "  item-249 at level 1: text: where ...  Show that:\n",
      "  item-250 at level 1: formula: \n",
      "  item-251 at level 1: text: so we ... stribution.\n",
      "  item-252 at level 1: text: Probl ...  show that:\n",
      "  item-253 at level 1: formula: \n",
      "  item-254 at level 1: text: where ... stribution.\n",
      "  item-255 at level 1: text: Probl ... e relation:\n",
      "  item-256 at level 1: formula: \n",
      "  item-257 at level 1: text: Probl ... e relation:\n",
      "  item-258 at level 1: formula: \n",
      "  item-259 at level 1: text: Probl ... tion 18.15.\n",
      "  item-260 at level 1: text: Probl ... econd line.\n",
      "  item-261 at level 1: text: Probl ... s given by:\n",
      "  item-262 at level 1: formula: \n",
      "  item-263 at level 1: text: Subst ... tion 18.28.\n",
      "  item-264 at level 1: text: Probl ...  show that:\n",
      "  item-265 at level 1: text: Probl ...  show that:\n",
      "  item-266 at level 1: formula: \n",
      "  item-267 at level 1: formula: \n",
      "  item-268 at level 1: text: Probl ... tion 18.38.\n",
      "  item-269 at level 1: text: Probl ... n this way?\n",
      "INFO:autogen.agents.experimental.document_agent.chroma_query_engine:Loading input doc: /home/ljf1/dis/mcp_hackathon/parsed_docs/UnderstandingDeepLearning_DiffusionModels.md\n",
      "INFO:autogen.agents.experimental.document_agent.docling_doc_ingest_agent:data_ingest_task context_variables: {'CompletedTaskCount': 1, 'DocumentsToIngest': [], 'DocumentsIngested': ['data/UnderstandingDeepLearning_DiffusionModels.pdf'], 'QueriesToRun': [Query(query_type=<QueryType.RAG_QUERY: 'RAG_QUERY'>, query='What is the difference between diffusion models and GANs?')], 'QueryResults': [], 'TaskInitiated': True}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m_Group_Tool_Executor\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_Wkos3RxYmB0K4jEY3GJDTYm4) *****\u001b[0m\n",
      "Data Ingestion Task Completed for data/UnderstandingDeepLearning_DiffusionModels.pdf\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: TaskManagerAgent\n",
      "\u001b[0m\n",
      "\u001b[33mTaskManagerAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "[Handing off to QueryAgent]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: QueryAgent\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mQueryAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_yqaJY8XZiI6h0kMtExrmb4eh): execute_rag_query *****\u001b[0m\n",
      "Arguments: \n",
      "{}\n",
      "\u001b[32m**********************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: _Group_Tool_Executor\n",
      "\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION execute_rag_query...\n",
      "Call ID: call_yqaJY8XZiI6h0kMtExrmb4eh\n",
      "Input arguments: {}\u001b[0m\n",
      "\u001b[33m_Group_Tool_Executor\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_yqaJY8XZiI6h0kMtExrmb4eh) *****\u001b[0m\n",
      "Diffusion models and GANs differ primarily in their approach to generating data. Diffusion models define a probabilistic framework where data is mapped through a series of latent variables, gradually blending with noise until it becomes indistinguishable from white noise. The reverse process, which is learned, removes the noise to generate realistic samples. This method allows diffusion models to produce high-quality samples that can exceed the realism of those produced by GANs. In contrast, GANs generate samples by training two networks, a generator and a discriminator, in a competitive setting, but they do not define a probability distribution over the data. Additionally, diffusion models are known for their ease of training compared to GANs.\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: QueryAgent\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mQueryAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "The difference between diffusion models and GANs (Generative Adversarial Networks) lies in their approaches to data generation:\n",
      "\n",
      "1. **Data Generation Process**:\n",
      "   - **Diffusion Models**: They use a probabilistic framework where data is transformed through a series of latent variables, gradually mixing with noise until it resembles white noise. The learned reverse process then removes the noise to generate realistic samples.\n",
      "   - **GANs**: They generate samples through a competitive training process involving two networks: a generator and a discriminator. The generator creates samples, while the discriminator evaluates them, but GANs do not define a probability distribution over the data.\n",
      "\n",
      "2. **Sample Quality**:\n",
      "   - Diffusion models can produce high-quality samples that may exceed the realism of those generated by GANs.\n",
      "\n",
      "3. **Training Complexity**:\n",
      "   - Diffusion models are generally easier to train compared to GANs, which can be challenging due to their adversarial nature.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: TaskManagerAgent\n",
      "\u001b[0m\n",
      "\u001b[33mTaskManagerAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "[Handing off to SummaryAgent]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: SummaryAgent\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mSummaryAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "Ingestions:\n",
      "1. Ingested data/UnderstandingDeepLearning_DiffusionModels.pdf\n",
      "\n",
      "Queries:\n",
      "1. What is the difference between diffusion models and GANs?\n",
      "Answer: The difference between diffusion models and GANs (Generative Adversarial Networks) lies in their approaches to data generation:\n",
      "\n",
      "1. Data Generation Process:\n",
      "   - Diffusion Models: They use a probabilistic framework where data is transformed through a series of latent variables, gradually mixing with noise until it resembles white noise. The learned reverse process then removes the noise to generate realistic samples.\n",
      "   - GANs: They generate samples through a competitive training process involving two networks: a generator and a discriminator. The generator creates samples, while the discriminator evaluates them, but GANs do not define a probability distribution over the data.\n",
      "\n",
      "2. Sample Quality:\n",
      "   - Diffusion models can produce high-quality samples that may exceed the realism of those generated by GANs.\n",
      "\n",
      "3. Training Complexity:\n",
      "   - Diffusion models are generally easier to train compared to GANs, which can be challenging due to their adversarial nature.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (0298fb48-b738-40da-94f6-20d9c765d6f0): No next speaker selected\u001b[0m\n",
      "\u001b[33mDocAgent\u001b[0m (to user):\n",
      "\n",
      "Ingestions:\n",
      "1. Ingested data/UnderstandingDeepLearning_DiffusionModels.pdf\n",
      "\n",
      "Queries:\n",
      "1. What is the difference between diffusion models and GANs?\n",
      "Answer: The difference between diffusion models and GANs (Generative Adversarial Networks) lies in their approaches to data generation:\n",
      "\n",
      "1. Data Generation Process:\n",
      "   - Diffusion Models: They use a probabilistic framework where data is transformed through a series of latent variables, gradually mixing with noise until it resembles white noise. The learned reverse process then removes the noise to generate realistic samples.\n",
      "   - GANs: They generate samples through a competitive training process involving two networks: a generator and a discriminator. The generator creates samples, while the discriminator evaluates them, but GANs do not define a probability distribution over the data.\n",
      "\n",
      "2. Sample Quality:\n",
      "   - Diffusion models can produce high-quality samples that may exceed the realism of those generated by GANs.\n",
      "\n",
      "3. Training Complexity:\n",
      "   - Diffusion models are generally easier to train compared to GANs, which can be challenging due to their adversarial nature.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (1655f083-33ef-4396-ac96-a123839954da): Maximum turns (1) reached\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "doc_agent = DocAgent(llm_config=llm_config, collection_name='summarise')\n",
    "run_response = doc_agent.run(\n",
    "    message = f\"ingest {DOC_PATH} and answer {QUERY}\",\n",
    "    max_turns=1,\n",
    ")\n",
    "run_response.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(DOC_PATH)\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# split the doc into smaller chunks i.e. chunk_size=500\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# get OpenAI Embedding model\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# embed the chunks as vectors and load them into the database\n",
    "db_chroma = Chroma.from_documents(chunks, embeddings, persist_directory=CHROMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the difference between diffusion models and GANs?\"\n",
    "docs_chroma = db_chroma.similarity_search_with_score(query, k=5)\n",
    "context_text = \"\\n\\n\".join([doc.page_content for doc, _score in docs_chroma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "Answer the question based on the above context: {question}.\n",
    "Provide a detailed answer.\n",
    "Don’t justify your answers.\n",
    "Don’t give information not mentioned in the CONTEXT INFORMATION.\n",
    "Do not say \"according to the context\" or \"mentioned in the context\" or similar.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36342/91517730.py:5: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  model = ChatOpenAI()\n",
      "/tmp/ipykernel_36342/91517730.py:6: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response_text = model.predict(prompt)\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = prompt_template.format(context=context_text, question=query)\n",
    "\n",
    "# call LLM model to generate the answer based on the given context and query\n",
    "model = ChatOpenAI()\n",
    "response_text = model.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Diffusion models synthesize higher quality images than other generative models, such as GANs, and are simple to train. They are a special case of a hierarchical VAE where the encoder quality of the results is quantitatively superior to GAN models in terms of Fréchet Inception Distance. Additionally, diffusion models have been shown to work with a large family of degradations that do not have to be stochastic, including masking, morphing, blurring, and pixelating. On the other hand, GANs do not define a probability distribution over the data like diffusion models do, and GANs require architectural constraints on the network for training.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
