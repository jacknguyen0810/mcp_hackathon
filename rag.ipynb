{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.agents.experimental.document_agent.chroma_query_engine:Using existing collection summarise from the database.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to DocAgent):\n",
      "\n",
      "ingest all documents in data/ and do Create a list of the top 20 most important concepts. For each concept, explain it in a VERY detailed manner and why it is important..\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33m_User\u001b[0m (to chat_manager):\n",
      "\n",
      "ingest all documents in data/ and do Create a list of the top 20 most important concepts. For each concept, explain it in a VERY detailed manner and why it is important..\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: DocumentTriageAgent\n",
      "\u001b[0m\n",
      "\u001b[33mDocumentTriageAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "{\"ingestions\":[{\"path_or_url\":\"data/\"}],\"queries\":[{\"query_type\":\"RAG_QUERY\",\"query\":\"Create a list of the top 20 most important concepts and explain each in detail.\"}]}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: TaskManagerAgent\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mTaskManagerAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_3pra6hnFbTXvOay7AWe31b6t): initiate_tasks *****\u001b[0m\n",
      "Arguments: \n",
      "{\"task_init_info\":{\"ingestions\":[{\"path_or_url\":\"data/\"}],\"queries\":[{\"query_type\":\"RAG_QUERY\",\"query\":\"Create a list of the top 20 most important concepts and explain each in detail.\"}]}}\n",
      "\u001b[32m*******************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: _Group_Tool_Executor\n",
      "\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION initiate_tasks...\n",
      "Call ID: call_3pra6hnFbTXvOay7AWe31b6t\n",
      "Input arguments: {'task_init_info': {'ingestions': [{'path_or_url': 'data/'}], 'queries': [{'query_type': 'RAG_QUERY', 'query': 'Create a list of the top 20 most important concepts and explain each in detail.'}]}}\u001b[0m\n",
      "\u001b[33m_Group_Tool_Executor\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_3pra6hnFbTXvOay7AWe31b6t) *****\u001b[0m\n",
      "Updated context variables with task decisions\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: TaskManagerAgent\n",
      "\u001b[0m\n",
      "\u001b[33mTaskManagerAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "[Handing off to DoclingDocIngestAgent]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: DoclingDocIngestAgent\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mDoclingDocIngestAgent\u001b[0m (to chat_manager):\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.agents.experimental.document_agent.document_utils:Detected directory. Listing files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m***** Suggested tool call (call_jsViNrcFA2qJUgQdDI4FLNju): data_ingest_task *****\u001b[0m\n",
      "Arguments: \n",
      "{}\n",
      "\u001b[32m*********************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: _Group_Tool_Executor\n",
      "\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION data_ingest_task...\n",
      "Call ID: call_jsViNrcFA2qJUgQdDI4FLNju\n",
      "Input arguments: {}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:docling.document_converter:Going to convert document batch...\n",
      "INFO:docling.document_converter:Initializing pipeline for StandardPdfPipeline with options hash abf069e0fb0f219e247d3d2b243ad857\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.pipeline.base_pipeline:Processing document UnderstandingDeepLearning_DiffusionModels.pdf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     17\u001b[39m doc_agent = DocAgent(llm_config=llm_config, collection_name=\u001b[33m'\u001b[39m\u001b[33msummarise\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     18\u001b[39m run_response = doc_agent.run(\n\u001b[32m     19\u001b[39m     message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mingest all documents in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDOC_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and do \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mQUERY\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     20\u001b[39m     max_turns=\u001b[32m1\u001b[39m,\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mrun_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m result = run_response.messages[\u001b[32m1\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     27\u001b[39m finalizer = ConversableAgent(\n\u001b[32m     28\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mFinalizer\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     29\u001b[39m     llm_config=llm_config,\n\u001b[32m     30\u001b[39m     system_message=\u001b[33m\"\u001b[39m\u001b[33mYour job is to clean up the results from the DocAgent. Return the results in a list format, including as much detail as possible. Return ONLY the list with no other additional text.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     31\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dis/MCPAgents/ag2/autogen/io/run_response.py:199\u001b[39m, in \u001b[36mRunResponse.process\u001b[39m\u001b[34m(self, processor)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, processor: Optional[EventProcessorProtocol] = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    198\u001b[39m     processor = processor \u001b[38;5;129;01mor\u001b[39;00m ConsoleEventProcessor()\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[43mprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dis/MCPAgents/ag2/autogen/io/processors/console_event_processor.py:19\u001b[39m, in \u001b[36mConsoleEventProcessor.process\u001b[39m\u001b[34m(self, response)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, response: \u001b[33m\"\u001b[39m\u001b[33mRunResponseProtocol\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevents\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dis/MCPAgents/ag2/autogen/io/run_response.py:138\u001b[39m, in \u001b[36mRunResponse._queue_generator\u001b[39m\u001b[34m(self, q)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    137\u001b[39m         \u001b[38;5;66;03m# Get an item from the queue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m         event = \u001b[43mq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust timeout as needed\u001b[39;00m\n\u001b[32m    140\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, InputRequestEvent):\n\u001b[32m    141\u001b[39m             event.content.respond = \u001b[38;5;28;01mlambda\u001b[39;00m response: \u001b[38;5;28mself\u001b[39m.iostream._output_stream.put(response)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/queue.py:180\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    178\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    179\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m item = \u001b[38;5;28mself\u001b[39m._get()\n\u001b[32m    182\u001b[39m \u001b[38;5;28mself\u001b[39m.not_full.notify()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from autogen.agents.experimental import DocAgent\n",
    "import os\n",
    "from autogen.agents.experimental import DocAgent\n",
    "from autogen import ConversableAgent\n",
    "llm_config = {'cache_seed': 42,\n",
    "                    'temperature': 0.9,\n",
    "                    'top_p': 0.05,\n",
    "                    'config_list': [{'model': 'gpt-4o-mini',\n",
    "                                    'api_key': os.getenv('OPENAI_API_KEY'),\n",
    "                                    'api_type': 'openai'}],\n",
    "                    'timeout': 1200}\n",
    "\n",
    "DOC_PATH = \"data/\"\n",
    "NUMBER = 20\n",
    "QUERY = f\"Create a list of the top {NUMBER} most important concepts. For each concept, explain it in a VERY detailed manner and why it is important.\"\n",
    "\n",
    "doc_agent = DocAgent(llm_config=llm_config, collection_name='summarise')\n",
    "run_response = doc_agent.run(\n",
    "    message = f\"ingest all documents in {DOC_PATH} and do {QUERY}.\",\n",
    "    max_turns=1,\n",
    "    \n",
    ")\n",
    "run_response.process()\n",
    "\n",
    "result = run_response.messages[1]['content']\n",
    "\n",
    "finalizer = ConversableAgent(\n",
    "    name=\"Finalizer\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Your job is to clean up the results from the DocAgent. Return the results in a list format, including as much detail as possible. Return ONLY the list with no other additional text.\",\n",
    ")\n",
    "\n",
    "finalizer_response = finalizer.run(\n",
    "    message=result,\n",
    "    max_turns=1,\n",
    ")\n",
    "finalizer_response.process()\n",
    "final_result = finalizer_response.messages[1]['content']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
